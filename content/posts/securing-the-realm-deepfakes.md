---
title: Securing the Realm - Deepfakes
date: 2025-08-08
slug: securing-the-realm-deepfakes
summary: Joined by Josh McDonald and Chris Lloyd-Jones from the MVP community to talk about deepfakes and shallow fakes, highlighting some potential issues.
feature_image: /static/images/secure_realm.jpg
---

<figure class="kg-card kg-embed-card">
    <div class="relative max-w-4xl mx-auto" style="padding-bottom: 56.25%;">
        <iframe class="absolute top-0 left-0 w-full h-full" src="https://www.youtube.com/embed/JqpfN8vmTxc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
    </div>
</figure>

<p>In this episode of "Securing the Realm," join myself, Josh McDonald and Chris Lloyd-Jones from the MVP community as we dive into the mystifying world of deepfakes and shallow fakes and their implications for security and media trust. We explore real examples of deepfakes, showcasing the state-of-the-art tools that make them possible, and take a look back at the evolution of this technology.</p>

<p>The discussion covers the implications for security and misinformation, exploring how far we've come and the challenges that lie ahead. We examine how detection of deepfakes relies on physiological signals and contextual clues, and why media literacy is crucial in combating misinformation.</p>

<p>Key takeaways include understanding that shallow fakes are easier to create than deepfakes, how real-time AI avatars can mimic human gestures and speech, and the importance of content provenance for trust in media. The technology is advancing faster than detection methods, making education campaigns and public awareness more critical than ever.</p>

<p>See more at the securing the realm GitHub: <a href="https://securingtherealm.github.io/">https://securingtherealm.github.io/</a></p>
